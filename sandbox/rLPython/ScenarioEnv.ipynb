{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\python38\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\python38\\lib\\site-packages (from gym) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\python38\\lib\\site-packages (from gym) (2.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable_baselines3 in c:\\python38\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy in c:\\python38\\lib\\site-packages (from stable_baselines3) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\python38\\lib\\site-packages (from stable_baselines3) (2.0.0)\n",
      "Requirement already satisfied: gym>=0.17 in c:\\python38\\lib\\site-packages (from stable_baselines3) (0.21.0)\n",
      "Requirement already satisfied: pandas in c:\\python38\\lib\\site-packages (from stable_baselines3) (1.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\python38\\lib\\site-packages (from stable_baselines3) (3.4.3)\n",
      "Requirement already satisfied: torch>=1.8.1 in c:\\python38\\lib\\site-packages (from stable_baselines3) (1.9.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\python38\\lib\\site-packages (from torch>=1.8.1->stable_baselines3) (3.7.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python38\\lib\\site-packages (from matplotlib->stable_baselines3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python38\\lib\\site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python38\\lib\\site-packages (from matplotlib->stable_baselines3) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python38\\lib\\site-packages (from matplotlib->stable_baselines3) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python38\\lib\\site-packages (from matplotlib->stable_baselines3) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\python38\\lib\\site-packages (from pandas->stable_baselines3) (2021.3)\n",
      "Requirement already satisfied: six in c:\\python38\\lib\\site-packages (from cycler>=0.10->matplotlib->stable_baselines3) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python38\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "!pip install stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Dict, MultiBinary, MultiDiscrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScenarioManager:\n",
    "    def getActionSpace(self):\n",
    "        return MultiDiscrete([6, 6, 2, 2])\n",
    "    def getObservationSpace(self):\n",
    "        return Dict({\"missiles\": Discrete(100), \n",
    "        \"expectedShipDamage\": MultiDiscrete([3,3,3,3,3,3]), \n",
    "        \"currentShipDamage\": MultiDiscrete([3,3,3,3,3,3]), \n",
    "        \"target1Defense\": MultiDiscrete([100,100,100,100,100,100]),\n",
    "        \"target2Defense\": MultiDiscrete([100,100,100,100,100,100]),\n",
    "        \"target3Defense\": MultiDiscrete([100,100,100,100,100,100]),\n",
    "        \"target4Defense\": MultiDiscrete([100,100,100,100,100,100]),\n",
    "        \"target5Defense\": MultiDiscrete([100,100,100,100,100,100]),\n",
    "        \"target6Defense\": MultiDiscrete([100,100,100,100,100,100]),\n",
    "        \"target1Targets\": MultiBinary(6),\n",
    "        \"target2Targets\": MultiBinary(6),\n",
    "        \"target3Targets\": MultiBinary(6),\n",
    "        \"target4Targets\": MultiBinary(6),\n",
    "        \"target5Targets\": MultiBinary(6),\n",
    "        \"target6Targets\": MultiBinary(6),\n",
    "        \"assets\": MultiDiscrete([100,100])})\n",
    "    def getRandomizedState(self):\n",
    "        return {\"missiles\": random.randint(1, 99),\n",
    "         \"expectedShipDamage\": \n",
    "         np.array([random.randint(0, 2), \n",
    "         random.randint(0, 2), \n",
    "         random.randint(0, 2), \n",
    "         random.randint(0, 2), \n",
    "         random.randint(0, 2), \n",
    "         random.randint(0, 2)]), \n",
    "         \"currentShipDamage\": np.array([0,0,0,0,0,0]),\n",
    "         \"target1Defense\": np.array([0,0,25,0,15,0]),\n",
    "         \"target2Defense\": np.array([0,0,0,25,0,15]),\n",
    "         \"target3Defense\": np.array([0,0,30,0,0,0]),\n",
    "         \"target4Defense\": np.array([0,0,0,30,0,0]),\n",
    "         \"target5Defense\": np.array([0,0,0,0,40,0]),\n",
    "         \"target6Defense\": np.array([0,0,0,0,0,40]),\n",
    "         \"target1Targets\": np.array([1, 0, 1, 0 , 0, 0]),\n",
    "         \"target2Targets\": np.array([0, 1, 0, 1 , 0, 0]),\n",
    "         \"target3Targets\": np.array([1, 0, 1, 0 , 0, 0]),\n",
    "         \"target4Targets\": np.array([0, 1, 0, 1 , 0, 0]),\n",
    "         \"target5Targets\": np.array([0, 0, 0, 0 , 1, 1]),\n",
    "         \"target6Targets\": np.array([0, 0, 0, 0 , 1, 1]),\n",
    "        #  \"target1Targets\": np.array([1, random.randint(0,1), random.randint(0,1), random.randint(0,1), random.randint(0,1), random.randint(0,1)]),\n",
    "        #  \"target2Targets\": np.array([random.randint(0,1), 1, random.randint(0,1), random.randint(0,1), random.randint(0,1), random.randint(0,1)]),\n",
    "        #  \"target3Targets\": np.array([random.randint(0,1), random.randint(0,1), 1, random.randint(0,1), random.randint(0,1), random.randint(0,1)]),\n",
    "        #  \"target4Targets\": np.array([random.randint(0,1), random.randint(0,1), random.randint(0,1), 1, random.randint(0,1), random.randint(0,1)]),\n",
    "        #  \"target5Targets\": np.array([random.randint(0,1), random.randint(0,1), random.randint(0,1), random.randint(0,1) , 1, random.randint(0,1)]),\n",
    "        #  \"target6Targets\": np.array([random.randint(0,1), random.randint(0,1), random.randint(0,1), random.randint(0,1) , random.randint(0,1), 1]),\n",
    "         \"assets\": np.array([random.randint(1, 99), random.randint(1, 99)])}\n",
    "    def getState(self, numberOfmissiles, numberOfJets, numberOfPilots, tD1, tD2, tD3, tD4, tD5, tD6):\n",
    "        return {\"missiles\": numberOfmissiles,\n",
    "         \"expectedShipDamage\": np.array([tD1, tD2, tD3, tD4, tD5, tD6]), \n",
    "         \"currentShipDamage\": np.array([0,0,0,0,0,0]),\n",
    "         \"target1Defense\": np.array([0,0,25,0,15,0]),\n",
    "         \"target2Defense\": np.array([0,0,0,25,0,15]),\n",
    "         \"target3Defense\": np.array([0,0,30,0,0,0]),\n",
    "         \"target4Defense\": np.array([0,0,0,30,0,0]),\n",
    "         \"target5Defense\": np.array([0,0,0,0,40,0]),\n",
    "         \"target6Defense\": np.array([0,0,0,0,0,40]),\n",
    "         \"target1Targets\": np.array([1, 0, 1, 0 , 0, 0]),\n",
    "         \"target2Targets\": np.array([0, 1, 0, 1 , 0, 0]),\n",
    "         \"target3Targets\": np.array([1, 0, 1, 0 , 0, 0]),\n",
    "         \"target4Targets\": np.array([0, 1, 0, 1 , 0, 0]),\n",
    "         \"target5Targets\": np.array([0, 0, 0, 0 , 1, 1]),\n",
    "         \"target6Targets\": np.array([0, 0, 0, 0 , 1, 1]),\n",
    "         \"assets\": np.array([numberOfJets ,numberOfPilots])}\n",
    "    def canAttack(self, state, sortiArray, ship1, ship2):\n",
    "        canAttack = False\n",
    "        reward = -100\n",
    "        # Check if can attack\n",
    "        for sorti in sortiArray:\n",
    "            if state[sorti][ship1] and state[sorti][ship2]:\n",
    "                canAttack = True\n",
    "                reward = 2\n",
    "                break\n",
    "        return canAttack, reward\n",
    "    def shouldAttack(self, state, defenseArray, ship):\n",
    "        reward = 0\n",
    "        shouldAttack = True\n",
    "        # Check if ship is already more damaged than expected\n",
    "        if state[\"currentShipDamage\"][ship] >= state[\"expectedShipDamage\"][ship]:\n",
    "            # Check to see if target posses a threat\n",
    "            if(state[\"currentShipDamage\"][ship] == 0 and state[defenseArray[ship]][ship] > 0):\n",
    "                # Reward for damaging a ship that is a threat?\n",
    "                reward = 0\n",
    "            else:\n",
    "                # no threat and already at expected damage\n",
    "                reward = -200\n",
    "                shouldAttack = False\n",
    "        else:\n",
    "            # targetted a ship worth targetting\n",
    "            reward = 50\n",
    "        return shouldAttack, reward\n",
    "    def defendShip(self, state, defenseArray, ship):\n",
    "        shotDown = False\n",
    "        length = len(state[defenseArray[ship]])\n",
    "        for index in range(0, length):\n",
    "            if(state[defenseArray[ship]][index] > 0):\n",
    "                roll = random.randint(0,100)\n",
    "                if(roll <= state[defenseArray[ship]][index]):\n",
    "                    shotDown = True\n",
    "        return shotDown\n",
    "    def shootShip(self, state, ship, defenseArray):\n",
    "        reward = 0\n",
    "        roll = random.randint(0, 100)\n",
    "        if roll <= 60:\n",
    "            # Should we reward more here?\n",
    "            state[\"currentShipDamage\"][ship] = max(1, state[\"currentShipDamage\"][ship])\n",
    "            for index in defenseArray:\n",
    "                state[index][ship] = 0\n",
    "        \n",
    "            roll = random.randint(0, 100)\n",
    "            if roll <= 50:\n",
    "                # Should we reward more here?\n",
    "                state[\"currentShipDamage\"][ship] = max(2, state[\"currentShipDamage\"][ship])\n",
    "        \n",
    "        return reward\n",
    "    def step(self, state, action):\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        reward = 0\n",
    "        done = False\n",
    "        numberOfTargets = 6\n",
    "        defenseArray = [\"target1Defense\", \"target2Defense\", \"target3Defense\", \"target4Defense\", \"target5Defense\", \"target6Defense\"]\n",
    "        sortieArray = [\"target1Targets\", \"target2Targets\", \"target3Targets\", \"target4Targets\", \"target5Targets\", \"target6Targets\"]\n",
    "\n",
    "        # Should we reward here or after hit or even after checking against expected damage?\n",
    "        ship1Index = action[0]\n",
    "        ship2Index = action[1]\n",
    "\n",
    "        canAttack , canAttackReward = self.canAttack(state, sortieArray, ship1Index, ship2Index)\n",
    "\n",
    "        if canAttack:\n",
    "            shouldAttack, shouldAttackReward1 = self.shouldAttack(state, sortieArray, ship1Index)\n",
    "            shouldAttack2, shouldAttackReward2 = self.shouldAttack(state, sortieArray, ship2Index)\n",
    "\n",
    "            shotDown1 = self.defendShip(state, defenseArray, ship1Index)\n",
    "            shotDown2 = self.defendShip(state, defenseArray, ship2Index)\n",
    "\n",
    "            if ship1Index == ship2Index:\n",
    "                if shotDown1:\n",
    "                    state[\"assets\"][0] -= 1\n",
    "                    state[\"assets\"][1] -= 1\n",
    "            else:\n",
    "                if shotDown1:\n",
    "                    state[\"assets\"][0] -= 1\n",
    "                    state[\"assets\"][1] -= 1\n",
    "                if shotDown2:\n",
    "                    state[\"assets\"][0] -= 1\n",
    "                    state[\"assets\"][1] -= 1\n",
    "\n",
    "            self.shootShip(state, ship1Index, defenseArray)\n",
    "            state[\"missiles\"] -= 1\n",
    "            if action[2] == 1:\n",
    "                self.shootShip(state, ship1Index, defenseArray)\n",
    "                state[\"missiles\"] -= 1\n",
    "            self.shootShip(state, ship2Index, defenseArray)\n",
    "            state[\"missiles\"] -= 1\n",
    "            if action[3] == 1:\n",
    "                self.shootShip(state, ship2Index, defenseArray)\n",
    "                state[\"missiles\"] -= 1\n",
    "\n",
    "            reward = canAttackReward + shouldAttackReward1 + shouldAttackReward2\n",
    "        else:\n",
    "            # Can't attack we are done\n",
    "            return state, canAttackReward, False, info\n",
    "        \n",
    "        # ############# Ideas #################\n",
    "        # Add bonus for end state for each asset, maybe more for pilots and jets\n",
    "        # Add offset rewards for pilots and jets\n",
    "        # Add a calculated ratio reward for threats in the defending arrays\n",
    "\n",
    "        # Add penatly for going over on assets\n",
    "        if state[\"missiles\"] < 0:\n",
    "            reward -= 200\n",
    "\n",
    "        if state [\"assets\"][0] < 0:\n",
    "            reward -= 200\n",
    "\n",
    "        if state [\"assets\"][1] < 0:\n",
    "            reward -= 200\n",
    "\n",
    "        isExpectedDamageMet = True\n",
    "        for shipIndex in range(0, numberOfTargets):\n",
    "            if state[\"currentShipDamage\"][shipIndex] < state[\"expectedShipDamage\"][shipIndex]:\n",
    "                isExpectedDamageMet = False\n",
    "                break\n",
    "\n",
    "        if isExpectedDamageMet:\n",
    "            reward += 300\n",
    "            done = True\n",
    "\n",
    "        if state[\"missiles\"] <= 0:\n",
    "            done = True\n",
    "\n",
    "        if state[\"assets\"][0] <= 0 or state[\"assets\"][1] <= 0:\n",
    "            done = True\n",
    "        \n",
    "        # Return step information\n",
    "        return state, reward, done, info\n",
    "\n",
    "class ScenarioEnv(Env):\n",
    "    def __init__(self, numberOfmissiles, numberOfJets, numberOfPilots, tD1, tD2, tD3, tD4, tD5, tD6):\n",
    "        manager = ScenarioManager()\n",
    "        self.manager = manager\n",
    "        # Actions we can take: 0 - Do Nothing, 1 - Launch\n",
    "        self.action_space = manager.getActionSpace()\n",
    "        # Target Damage state array: 0 - Untouched, 1 - Disabled, 2 - Destroyed\n",
    "        self.observation_space = manager.getObservationSpace()\n",
    "        # store initial state\n",
    "        self.numberOfmissiles = numberOfmissiles\n",
    "        self.numberOfJets = numberOfJets\n",
    "        self.numberOfPilots = numberOfPilots\n",
    "        self.tD1 = tD1\n",
    "        self.tD2 = tD2\n",
    "        self.tD3 = tD3\n",
    "        self.tD4 = tD4\n",
    "        self.tD5 = tD5\n",
    "        self.tD6 = tD6\n",
    "        # Set start state\n",
    "        self.state = self.manager.getState(self.numberOfmissiles, self.numberOfJets, self.numberOfPilots, self.tD1, self.tD2, self.tD3, self.tD4, self.tD5, self.tD6)\n",
    "\n",
    "    def step(self, action):\n",
    "        # Return step information\n",
    "        return self.manager.step(self.state, action)\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset shower temperature\n",
    "        self.state = self.manager.getState(self.numberOfmissiles, self.numberOfJets, self.numberOfPilots, self.tD1, self.tD2, self.tD3, self.tD4, self.tD5, self.tD6)\n",
    "        return self.state\n",
    "\n",
    "class TrainingScenarioEnv(Env):\n",
    "    def __init__(self):\n",
    "        manager = ScenarioManager()\n",
    "        self.manager = manager\n",
    "        # Actions we can take: 0 - Do Nothing, 1 - Launch\n",
    "        self.action_space = manager.getActionSpace()\n",
    "        # Target Damage state array: 0 - Untouched, 1 - Disabled, 2 - Destroyed\n",
    "        self.observation_space = manager.getObservationSpace()\n",
    "        # Set start state\n",
    "        self.state = manager.getRandomizedState()\n",
    "\n",
    "    def step(self, action):\n",
    "        # Return step information\n",
    "        return self.manager.step(self.state, action)\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset shower temperature\n",
    "        self.state = self.manager.getRandomizedState()\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingEnv=TrainingScenarioEnv()\n",
    "check_env(trainingEnv, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Scenario Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarioEnv = ScenarioEnv(13, 19, 21, 2, 1, 1, 1, 0, 0)\n",
    "check_env(scenarioEnv, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "trainingEnv.reset()\n",
    "model = PPO(\"MultiInputPolicy\", scenarioEnv, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_56\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 13.6      |\n",
      "|    ep_rew_mean     | -1.24e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 735       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 2         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20856/1300916049.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#model.learn(total_timesteps=400000)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    299\u001b[0m     ) -> \"PPO\":\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         return super(PPO, self).learn(\n\u001b[0m\u001b[0;32m    302\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             \u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;31m# Convert to pytorch tensor or to TensorDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[0mobs_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs_as_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                 \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlog\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \"\"\"\n\u001b[1;32m--> 586\u001b[1;33m         \u001b[0mlatent_pi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_vf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_sde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_latent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[1;31m# Evaluate the values for the given observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_vf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36m_get_latent\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    602\u001b[0m         \"\"\"\n\u001b[0;32m    603\u001b[0m         \u001b[1;31m# Preprocess the observation if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[0mlatent_pi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_vf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\stable_baselines3\\common\\policies.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \"\"\"\n\u001b[0;32m    126\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No features extractor was set\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mpreprocessed_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\stable_baselines3\\common\\preprocessing.py\u001b[0m in \u001b[0;36mpreprocess_obs\u001b[1;34m(obs, observation_space, normalize_images)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mpreprocessed_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_obs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mpreprocessed_obs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize_images\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpreprocessed_obs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\stable_baselines3\\common\\preprocessing.py\u001b[0m in \u001b[0;36mpreprocess_obs\u001b[1;34m(obs, observation_space, normalize_images)\u001b[0m\n\u001b[0;32m    113\u001b[0m             [\n\u001b[0;32m    114\u001b[0m                 \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnvec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             ],\n\u001b[0;32m    117\u001b[0m             \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;31m# split_size_or_sections. The branching code is in _tensor.py, which we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;31m# call here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_size_or_sections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, split_size, dim)\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 30ish minute training\n",
    "#model.learn(total_timesteps=400000)\n",
    "\n",
    "model.learn(total_timesteps=5000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Long_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"Long_PPO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainingEnv.reset()\n",
    "#evaluate_policy(model, trainingEnv, n_eval_episodes=1, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(767.988, 107.29335420239224)"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarioEnv.reset()\n",
    "evaluate_policy(model, scenarioEnv, n_eval_episodes=1000, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:102 Action:[2 2 0 0] State:[11, array([2, 1, 1, 1, 0, 0]), array([0, 0, 0, 0, 0, 0]), array([18, 20])]\n",
      "Score:204 Action:[2 2 0 0] State:[9, array([2, 1, 1, 1, 0, 0]), array([0, 0, 1, 0, 0, 0]), array([18, 20])]\n",
      "Score:306 Action:[3 3 0 0] State:[7, array([2, 1, 1, 1, 0, 0]), array([0, 0, 1, 2, 0, 0]), array([18, 20])]\n",
      "Score:408 Action:[0 0 0 0] State:[5, array([2, 1, 1, 1, 0, 0]), array([1, 0, 1, 2, 0, 0]), array([18, 20])]\n",
      "Score:510 Action:[0 0 0 0] State:[3, array([2, 1, 1, 1, 0, 0]), array([2, 0, 1, 2, 0, 0]), array([18, 20])]\n",
      "Score:912 Action:[1 1 0 1] State:[0, array([2, 1, 1, 1, 0, 0]), array([2, 2, 1, 2, 0, 0]), array([18, 20])]\n"
     ]
    }
   ],
   "source": [
    "scenarioEnv = ScenarioEnv(13, 19, 21, 2, 1, 1, 1, 0, 0)\n",
    "sampleEnvObs = scenarioEnv.reset()\n",
    "done = False\n",
    "score = 0 \n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(sampleEnvObs)\n",
    "    sampleEnvObs, reward, done, info = scenarioEnv.step(action)\n",
    "    score+=reward\n",
    "    print('Score:{} Action:{} State:{}'.format(score, action, [sampleEnvObs[\"missiles\"],sampleEnvObs[\"expectedShipDamage\"], sampleEnvObs[\"currentShipDamage\"], sampleEnvObs[\"assets\"]]))\n",
    "scenarioEnv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:102 Action:[1 1 1 1] State:[9, array([2, 1, 1, 1, 0, 0]), array([0, 0, 0, 0, 0, 0]), array([19, 21])]\n"
     ]
    }
   ],
   "source": [
    "scenarioEnv = ScenarioEnv(13, 19, 21, 2, 1, 1, 1, 0, 0)\n",
    "sampleEnvObs = scenarioEnv.reset()\n",
    "done = False\n",
    "score = 0 \n",
    "\n",
    "sampleEnvObs, reward, done, info = scenarioEnv.step([2,2,1,1])\n",
    "score+=reward\n",
    "print('Score:{} Action:{} State:{}'.format(score, action, [sampleEnvObs[\"missiles\"],sampleEnvObs[\"expectedShipDamage\"], sampleEnvObs[\"currentShipDamage\"], sampleEnvObs[\"assets\"]]))\n",
    "scenarioEnv.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
