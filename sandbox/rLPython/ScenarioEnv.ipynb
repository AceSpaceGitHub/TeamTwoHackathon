{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://sourceforge.net/projects/swig/files/swigwin/swigwin-4.0.2/swigwin-4.0.2.zip/download?use_mirror=ixpeering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\python38\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\python38\\lib\\site-packages (from gym) (1.21.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\python38\\lib\\site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: stable_baselines3[extra] in c:\\python38\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (1.9.1)\n",
      "Requirement already satisfied: numpy in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (1.21.2)\n",
      "Requirement already satisfied: pandas in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (1.3.4)\n",
      "Requirement already satisfied: gym>=0.17 in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (3.4.3)\n",
      "Requirement already satisfied: psutil in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (5.8.0)\n",
      "Requirement already satisfied: opencv-python in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (4.5.3.56)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (0.2.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (2.7.0)\n",
      "Requirement already satisfied: pillow in c:\\python38\\lib\\site-packages (from stable_baselines3[extra]) (8.4.0)\n",
      "Requirement already satisfied: six in c:\\python38\\lib\\site-packages (from atari-py~=0.2.0->stable_baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (0.14.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (58.2.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (3.18.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (1.41.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (2.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\python38\\lib\\site-packages (from tensorboard>=2.2.0->stable_baselines3[extra]) (0.37.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\python38\\lib\\site-packages (from torch>=1.8.1->stable_baselines3[extra]) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python38\\lib\\site-packages (from matplotlib->stable_baselines3[extra]) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python38\\lib\\site-packages (from matplotlib->stable_baselines3[extra]) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python38\\lib\\site-packages (from matplotlib->stable_baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python38\\lib\\site-packages (from matplotlib->stable_baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\python38\\lib\\site-packages (from pandas->stable_baselines3[extra]) (2021.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable_baselines3[extra]) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable_baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable_baselines3[extra]) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable_baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable_baselines3[extra]) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable_baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable_baselines3[extra]) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable_baselines3[extra]) (2021.10.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable_baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable_baselines3[extra]) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "!pip install stable_baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Types of Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building an Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScenarioEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take: 0 - Do Nothing, 1 - Launch\n",
    "        self.action_space = Discrete(7)\n",
    "        # Target Damage state array: 0 - Untouched, 1 - Disabled, 2 - Destroyed\n",
    "        self.observation_space = MultiDiscrete([100, 3, 3, 3, 3, 3, 3, 14, 14, 14, 14, 14, 14])\n",
    "        # Set start state\n",
    "        self.state = np.array([14, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=np.int64)\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        numberOfTargets = 6\n",
    "        targetsOffset = 1\n",
    "        # Apply action\n",
    "        if action == 0:\n",
    "            reward = 0\n",
    "        elif action > 0 and action <= numberOfTargets:\n",
    "            target = action - 1\n",
    "            reward = 1\n",
    "            expectedDamageIndex = targetsOffset + (target)\n",
    "            currentDamageIndex = targetsOffset + (target + numberOfTargets)\n",
    "            self.state[currentDamageIndex] += 1\n",
    "            if self.state[currentDamageIndex] > self.state[expectedDamageIndex]:\n",
    "                reward = -5\n",
    "        else:\n",
    "            reward = 0\n",
    "        \n",
    "        shouldReward = True\n",
    "        for myTarget in range(1, numberOfTargets):\n",
    "            expectedDamageIndex = myTarget\n",
    "            currentDamageIndex = myTarget + numberOfTargets\n",
    "            if self.state[currentDamageIndex] != self.state[expectedDamageIndex]:\n",
    "                shouldReward = False\n",
    "                break\n",
    "        \n",
    "        if shouldReward:\n",
    "            reward = 100\n",
    "            done = True\n",
    "\n",
    "        # Reduce shower length by 1 second\n",
    "        self.state[0] -= 1\n",
    "\n",
    "        # Check if shower is done\n",
    "        if self.state[0] <= 0:\n",
    "            done = True\n",
    "\n",
    "        # Apply temperature noise\n",
    "        # self.state += random.randint(-1,1)\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "\n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset shower temperature\n",
    "        self.state = np.array([14, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=np.int64)\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=ScenarioEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13,  2,  1,  1,  1,  0,  0,  0,  0,  0,  0,  1,  0], dtype=int64),\n",
       " -5,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space\n",
    "env.observation_space.contains(env.reset())\n",
    "env.step(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  2,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-36\n",
      "Episode:2 Score:-25\n",
      "Episode:3 Score:-35\n",
      "Episode:4 Score:-42\n",
      "Episode:5 Score:-31\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_15\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.8     |\n",
      "|    ep_rew_mean     | -31.8    |\n",
      "| time/              |          |\n",
      "|    fps             | 894      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.8        |\n",
      "|    ep_rew_mean          | -26         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012920099 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.00463     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.4        |\n",
      "|    ep_rew_mean          | -16.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013980908 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.00679     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.4        |\n",
      "|    ep_rew_mean          | -14.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017075133 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.0151      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 520         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 12.3       |\n",
      "|    ep_rew_mean          | 9.33       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 431        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01852933 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.75      |\n",
      "|    explained_variance   | 0.025      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 232        |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0297    |\n",
      "|    value_loss           | 501        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.9        |\n",
      "|    ep_rew_mean          | 21.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 390         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010326399 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 499         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 1.08e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.3        |\n",
      "|    ep_rew_mean          | 32.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010918461 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 595         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 1.24e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.3        |\n",
      "|    ep_rew_mean          | 50          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 341         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012617091 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 706         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 1.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.93        |\n",
      "|    ep_rew_mean          | 70.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 328         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008590799 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 710         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.55        |\n",
      "|    ep_rew_mean          | 71.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014384741 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 888         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.39        |\n",
      "|    ep_rew_mean          | 88.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 312         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009382717 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 612         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.39        |\n",
      "|    ep_rew_mean          | 86          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 308         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009465365 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 693         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.65        |\n",
      "|    ep_rew_mean          | 91.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012316925 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 479         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.58        |\n",
      "|    ep_rew_mean          | 93          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010130236 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 443         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 965         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.21        |\n",
      "|    ep_rew_mean          | 98.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012590583 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 322         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 805         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.68       |\n",
      "|    ep_rew_mean          | 102        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 298        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 109        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01387018 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0.693      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 135        |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 372        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.84        |\n",
      "|    ep_rew_mean          | 97          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029233124 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.988      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.35      |\n",
      "|    ep_rew_mean          | 103       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 311       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 118       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0286485 |\n",
      "|    clip_fraction        | 0.349     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.956    |\n",
      "|    explained_variance   | 0.687     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 151       |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -0.0194   |\n",
      "|    value_loss           | 358       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.32        |\n",
      "|    ep_rew_mean          | 103         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037229937 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.4        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.25        |\n",
      "|    ep_rew_mean          | 103         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036916245 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00766    |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.31        |\n",
      "|    ep_rew_mean          | 103         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023572987 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.95        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.15        |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 340         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011363743 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.78       |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.16        |\n",
      "|    ep_rew_mean          | 103         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011877777 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.06       |\n",
      "|    ep_rew_mean          | 104        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 354        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 138        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01138097 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.734     |\n",
      "|    explained_variance   | 0.699      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 108        |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.00908   |\n",
      "|    value_loss           | 227        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03        |\n",
      "|    ep_rew_mean          | 104         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015104925 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0833      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x28c6e61c400>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python38\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(104.0, 0.0)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=1000, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:1 Action:2 State:[13  2  1  1  1  0  0  0  1  0  0  0  0]\n",
      "Episode:1 Score:2 Action:3 State:[12  2  1  1  1  0  0  0  1  1  0  0  0]\n",
      "Episode:1 Score:3 Action:1 State:[11  2  1  1  1  0  0  1  1  1  0  0  0]\n",
      "Episode:1 Score:4 Action:1 State:[10  2  1  1  1  0  0  2  1  1  0  0  0]\n",
      "Episode:1 Score:104 Action:4 State:[9 2 1 1 1 0 0 2 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "        print('Episode:{} Score:{} Action:{} State:{}'.format(episode, score, action, obs))\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
